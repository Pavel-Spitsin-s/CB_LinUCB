{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mushroom Dataset Experiment\n",
    "\n",
    "This notebook demonstrates bandit algorithms on the Mushroom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbandits\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdynamic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DLinUCB\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mushroom\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from bandits.simple import UCB, EpsilonGreedy\n",
    "from bandits.linear import LinUCBDisjoint, LinUCBHybrid\n",
    "from bandits.dynamic import DLinUCB\n",
    "from data.datasets import Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bandit configurations\n",
    "k = 2\n",
    "bandit_configs = [\n",
    "    {'name': 'UCB (α=1.0)', 'class': UCB, 'params': {'alpha': 1.0}},\n",
    "    {'name': 'LinUCBDisjoint (α=1.0)', 'class': LinUCBDisjoint, 'params': {'alpha': 1.0}},\n",
    "    {'name': 'LinUCBHybrid (α=1.0)', 'class': LinUCBHybrid, 'params': {'alpha': 1.0}},\n",
    "    {'name': 'DLinUCB (α=1.0, ɣ=0.95)', 'class': DLinUCB, 'params': {'alpha': 1.0}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `parser='auto'` with dense data requires pandas to be installed. Alternatively, explicitly set `parser='liac-arff'`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/utils/_optional_dependencies.py:42\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:1059\u001b[39m, in \u001b[36mfetch_openml\u001b[39m\u001b[34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[39m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m     \u001b[43mcheck_pandas_support\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m`fetch_openml`\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/utils/_optional_dependencies.py:46\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m requires pandas.\u001b[39m\u001b[33m\"\u001b[39m.format(caller_name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: `fetch_openml` requires pandas.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run experiments with random_k_features=30\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mushroom_experiment = \u001b[43mMushroom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_k_features\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m results = mushroom_experiment.run_experiments(bandit_configs, num_experiments=\u001b[32m10\u001b[39m, num_rounds=\u001b[32m2000\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/notebooks/../experiments/classification.py:18\u001b[39m, in \u001b[36mClassificationExperiment.__init__\u001b[39m\u001b[34m(self, k, random_k_features, normalize, random_state)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.normalize = normalize\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.random_state = random_state\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mself\u001b[39m.X, \u001b[38;5;28mself\u001b[39m.y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.X, \u001b[38;5;28mself\u001b[39m.y = \u001b[38;5;28mself\u001b[39m._preprocess_data(\u001b[38;5;28mself\u001b[39m.X, \u001b[38;5;28mself\u001b[39m.y, \u001b[38;5;28mself\u001b[39m.normalize)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.n_arms = \u001b[38;5;28mlen\u001b[39m(np.unique(\u001b[38;5;28mself\u001b[39m.y))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/notebooks/../data/datasets.py:13\u001b[39m, in \u001b[36mMushroom.load_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     mushroom = \u001b[43mfetch_openml\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmushroom\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_frame\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mushroom.data, mushroom.target\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:1072\u001b[39m, in \u001b[36mfetch_openml\u001b[39m\u001b[34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[39m\n\u001b[32m   1067\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1068\u001b[39m             err_msg = (\n\u001b[32m   1069\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing `parser=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparser\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m` with dense data requires pandas to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstalled. Alternatively, explicitly set `parser=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mliac-arff\u001b[39m\u001b[33m'\u001b[39m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_sparse:\n\u001b[32m   1075\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m as_frame:\n",
      "\u001b[31mImportError\u001b[39m: Using `parser='auto'` with dense data requires pandas to be installed. Alternatively, explicitly set `parser='liac-arff'`."
     ]
    }
   ],
   "source": [
    "# Run experiments with random_k_features=30\n",
    "mushroom_experiment = Mushroom(k=k, random_k_features=30)\n",
    "results = mushroom_experiment.run_experiments(bandit_configs, num_experiments=10, num_rounds=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Feature Counts\n",
    "\n",
    "We will test how the number of features affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 5 features\n",
    "mushroom_experiment = Mushroom(k=k, random_k_features=5)\n",
    "results_5 = mushroom_experiment.run_experiments(bandit_configs, num_experiments=10, num_rounds=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 25 features\n",
    "mushroom_experiment = Mushroom(k=k, random_k_features=25)\n",
    "results_25 = mushroom_experiment.run_experiments(bandit_configs, num_experiments=10, num_rounds=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `parser='auto'` with dense data requires pandas to be installed. Alternatively, explicitly set `parser='liac-arff'`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/utils/_optional_dependencies.py:42\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:1059\u001b[39m, in \u001b[36mfetch_openml\u001b[39m\u001b[34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[39m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m     \u001b[43mcheck_pandas_support\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m`fetch_openml`\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/utils/_optional_dependencies.py:46\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m requires pandas.\u001b[39m\u001b[33m\"\u001b[39m.format(caller_name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: `fetch_openml` requires pandas.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test with 45 features\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mushroom_experiment = \u001b[43mMushroom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_k_features\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m45\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m results_45 = mushroom_experiment.run_experiments(bandit_configs, num_experiments=\u001b[32m10\u001b[39m, num_rounds=\u001b[32m2000\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/notebooks/../experiments/classification.py:18\u001b[39m, in \u001b[36mClassificationExperiment.__init__\u001b[39m\u001b[34m(self, k, random_k_features, normalize, random_state)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.normalize = normalize\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.random_state = random_state\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mself\u001b[39m.X, \u001b[38;5;28mself\u001b[39m.y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.X, \u001b[38;5;28mself\u001b[39m.y = \u001b[38;5;28mself\u001b[39m._preprocess_data(\u001b[38;5;28mself\u001b[39m.X, \u001b[38;5;28mself\u001b[39m.y, \u001b[38;5;28mself\u001b[39m.normalize)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.n_arms = \u001b[38;5;28mlen\u001b[39m(np.unique(\u001b[38;5;28mself\u001b[39m.y))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/notebooks/../data/datasets.py:13\u001b[39m, in \u001b[36mMushroom.load_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     mushroom = \u001b[43mfetch_openml\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmushroom\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_frame\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mushroom.data, mushroom.target\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CB_LinUCB/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:1072\u001b[39m, in \u001b[36mfetch_openml\u001b[39m\u001b[34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[39m\n\u001b[32m   1067\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1068\u001b[39m             err_msg = (\n\u001b[32m   1069\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing `parser=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparser\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m` with dense data requires pandas to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstalled. Alternatively, explicitly set `parser=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mliac-arff\u001b[39m\u001b[33m'\u001b[39m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_sparse:\n\u001b[32m   1075\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m as_frame:\n",
      "\u001b[31mImportError\u001b[39m: Using `parser='auto'` with dense data requires pandas to be installed. Alternatively, explicitly set `parser='liac-arff'`."
     ]
    }
   ],
   "source": [
    "# Test with 45 features\n",
    "mushroom_experiment = Mushroom(k=k, random_k_features=45)\n",
    "results_45 = mushroom_experiment.run_experiments(bandit_configs, num_experiments=10, num_rounds=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare_parameter_sensitivity\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Extract just the results for LinUCBDisjoint\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results_list = [\u001b[43mresults_5\u001b[49m, results_25, results_45]\n\u001b[32m      6\u001b[39m feature_counts = [\u001b[32m5\u001b[39m, \u001b[32m25\u001b[39m, \u001b[32m45\u001b[39m]\n\u001b[32m      7\u001b[39m compare_parameter_sensitivity(results_list, feature_counts, \u001b[33m'\u001b[39m\u001b[33mfeature_count\u001b[39m\u001b[33m'\u001b[39m, metric=\u001b[33m'\u001b[39m\u001b[33mctr\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results_5' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare performance with different feature counts\n",
    "from utils.visualization import compare_parameter_sensitivity\n",
    "\n",
    "# Extract just the results for LinUCBDisjoint\n",
    "results_list = [results_5, results_25, results_45]\n",
    "feature_counts = [5, 25, 45]\n",
    "compare_parameter_sensitivity(results_list, feature_counts, 'feature_count', metric='ctr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
