% !TeX program = xelatex
\documentclass[10pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usetheme{Madrid}

\title{LinUCB в Multiarmed bandits:\\ Задача онлайн-классификации}
\author{Спицын Павел, Мурзин Илья, Зинатулин Артём, Никифорова Анна, Глазов Иван, Газизуллин Нияз}
\institute{Студкемп МФТИ x Яндекс}
\date{\today}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Содержание}
  \tableofcontents
\end{frame}

\section{Введение}
\begin{frame}{Введение в проблему}
  \begin{itemize}
    \item Контекстные многорукие бандиты (Contextual Bandits) объединяют элементы классического \emph{exploration-exploitation}.
    \item Задача: на каждом шаге выбирать действие (руку) на основе контекста и кумулятивного вознаграждения.
    \item Применения: рекомендации, онлайн-задачи, принятие решений при неопределённости, торговые стратегии.
  \end{itemize}
\end{frame}

\section{Постановка задачи}
\begin{frame}{Формализация задачи}
  На каждом шаге $t=1,2,\dots$:
  \begin{enumerate}
    \item Наблюдаем контексты $\{x_{t,a}\}_{a\in A_t}$, $x_{t,a}\in\mathbb{R}^d$.
    \item Выбираем действие $a_t\in A_t$ по политике $\pi$.
    \item Получаем вознаграждение $r_{t,a_t}\in[0,1]$, остальные $r_{t,a}$ неизвестны.
  \end{enumerate}
  Цель: максимизировать суммарный ожидаемый доход $\displaystyle \sum_{t=1}^T r_{t,a_t}$ или минимизировать регрет
  \[ R(T)=\mathbb{E}\Bigl[\sum_t r_{t,a^*_t}-\sum_t r_{t,a_t}\Bigr]. \]
\end{frame}
\begin{frame}{Алгоритм $\boldsymbol{\varepsilon}$-greedy}
  \begin{itemize}
    \item Идея: в каждом шаге с вероятностью $1-\varepsilon$ выбираем действие, максимизирующее текущую оценку
    $$a_t = \arg\max_a \hat{\mu}_{t-1,a},$$
    с вероятностью $\varepsilon$ — случайное действие для исследования.
    \item Оценка среднего вознаграждения для каждой руки $a$ после $t-1$ запусков:
    $$\hat{\mu}_{t-1,a} = \frac{1}{N_{t-1}(a)} \sum_{s: a_s = a} r_s,$$
    где $N_{t-1}(a)$ — число выборов руки $a$ до состояния $t$.
    \item Параметр $\varepsilon\in[0,1]$ балансирует exploitation и exploration:
    \begin{itemize}
      \item Малое $\varepsilon$ — мало исследования, долгая сходимость.
      \item Большое $\varepsilon$ — при нахождении оптимальной ручки много неоптимальных действий.
    \end{itemize}
    \item Простейшая стратегия, легко реализуется и анализируется.
  \end{itemize}
\end{frame}

%% Слайд UCB1
\begin{frame}{Алгоритм UCB (Upper Confidence Bound)}
  \begin{itemize}
    \item Каждый шаг $t$: для каждой руки $a$ вычисляем доверительный интервал:
    $$UCB_{t,a} = \hat{\mu}_{t-1,a} + \alpha\sqrt{\frac{2\ln t}{N_{t-1}(a)}},$$
    где
    \begin{itemize}
      \item $\hat{\mu}_{t-1,a}$ — среднее вознаграждение руки $a$ до шага $t$.
      \item $N_{t-1}(a)$ — число выборов руки $a$ до шага $t$.
      \item $\alpha$ — зачастую берут $\alpha=1$, \!может быть настроен.
    \end{itemize}
    \item Выбор руки, максимизирующей UCB:
    $$a_t = \arg\max_a UCB_{t,a}.$$  
    \item Классический метод, гарантирующий регрет $O\bigl(\sqrt{|A|T\ln T}\bigr)$ для $K$ рук и $T$ шагов.
    \item Интуиция: рука с небольшим $N(a)$ получает большой бонус и исследуется чаще.
  \end{itemize}
\end{frame}
\section{Метод LinUCB}
\begin{frame}{Модель линейного вознаграждения}
  Предполагается, что
  \[
    \mathbb{E}[r_{t,a}\mid x_{t,a}]=x_{t,a}^\top \theta^*_a,
  \]
  где $\theta^*_a\in\mathbb{R}^d$ неизвестен.\
  Применяется \emph{ridge regression} для оценки:
  \[
    \hat{\theta}_a=(D_a^\top D_a + I)^{-1} D_a^\top c_a.
  \]
  Оценка верхней границы доверительного интервала:
  \[
    p_{t,a}=x_{t,a}^\top \hat{\theta}_a + \alpha\sqrt{x_{t,a}^\top A_a^{-1} x_{t,a}}.
  \]
\end{frame}

\begin{frame}[fragile]{Алгоритм LinUCB}
  \begin{block}{LinUCB (Disjoint)}
  \begin{enumerate}
    \item Инициализация для каждого действия $a$: $A_a=I_d$, $b_a=0_d$.
    \item Для шага $t=1\dots T$:
      \begin{itemize}
        \item Наблюдаем $\{x_{t,a}\}_{a\in A_t}$.
        \item Для каждого $a$ вычисляем:
        \[
          \hat{\theta}_a=A_a^{-1}b_a,\quad p_{t,a}=\hat{\theta}_a^\top x_{t,a}+\alpha\sqrt{x_{t,a}^\top A_a^{-1}x_{t,a}}.
        \]
        \item Выбираем $a_t=\arg\max_a p_{t,a}$, наблюдаем $r_{t,a_t}$.
        \item Обновляем:
        \[
          A_{a_t} \leftarrow A_{a_t} + x_{t,a_t}x_{t,a_t}^\top,
          \quad b_{a_t} \leftarrow b_{a_t} + r_{t,a_t} x_{t,a_t}.
        \]
      \end{itemize}
  \end{enumerate}
  \end{block}
\end{frame}

\section{Используемые данные}
\begin{frame}{Датасеты}
  \begin{itemize}
    \item \textbf{Bibtex}: многометочная классификация публикаций.
    \item \textbf{Mushrooms}: бинарная классификация съедобности грибов.
    \item \textbf{Iris}: классификация цветков Ирисов.
  \end{itemize}
  Особенности: разные размерности и характеристики пространства признаков.
\end{frame}

\section{Эксперименты и результаты}
\begin{frame}{Методология эксперимента}
  \begin{itemize}
    \item Онлайн-имитация: на каждом примере $i$ использовать LinUCB для выбора метки как «действие» и получать награду (1–точен, 0–ошибка).
    \item Сравнение с базовыми методами: $\varepsilon$-greedy, UCB без контекста.
    \item Показатели: кумулятивный регрет, среднее вознаграждение за раунд.
  \end{itemize}
\end{frame}
\begin{frame}{Результаты}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{ebut.jpg}
  \end{center}
\end{frame}
\begin{frame}{Результаты}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{ebut2.jpg}
  \end{center}
\end{frame}
\begin{frame}{Результаты}
  \begin{table}[ht]
    \centering
    \begin{tabular}{lccc}
      \hline
      \textbf{Метод} & \textbf{Bibtex Regret} & \textbf{Mushrooms Regret} & \textbf{Iris Regret} \\
      \hline
      $\varepsilon$-greedy &  3281.0 &  2434.0 & 1337.0 \\
      UCB (context-free) & 3874.0 & 2505.0 & 1308.0 \\
      \textbf{LinUCB } &2619.0& 32.0 & 136.0 \\
      \hline
    \end{tabular}
    \caption{Кумулятивный регрет различных методов}
  \end{table}
  \vspace{1em}
  % Графики и регрет
  \begin{itemize}
    \item LinUCB демонстрирует более быстрый спад регрета.
    \item Что не удивительно, так как в задаче важен контекст.
     \item Для датасетов большой размерности проблемно применять подобные методы.
  \end{itemize}
\end{frame}
\begin{frame}{Алгоритм EXP4}
  \begin{itemize}
    \item EXP4 (Exponential-weight algorithm for Exploration and Exploitation using Experts).
    \item Имеется $N$ экспертов, каждый эксперт $i$ задаёт распределение $\xi_{t,i} = (\xi_{t,i,1}, ..., \xi_{t,i,K})$ над действиями.
    \item Веса экспертов инициализируются $w_{1,i} = 1$. Обновление весов:
    \[
    w_{t+1,i} = w_{t,i} \exp\left(\frac{\gamma}{K} \cdot \hat{y}_{t,i}\right),
    \]
    где 
    \begin{align*}
    p_{t,a} &= (1-\gamma)\frac{\sum_{i=1}^N w_{t,i}\xi_{t,i,a}}{W_t} + \frac{\gamma}{K}, \\
    \hat{r}_{t,a} &= \begin{cases}
    \frac{r_{t,a}}{p_{t,a}}, & \text{если } a = a_t \\
    0, & \text{иначе}
    \end{cases} \\
    \hat{y}_{t,i} &= \xi_{t,i} \cdot \hat{r}_t = \sum_{a=1}^K \xi_{t,i,a}\hat{r}_{t,a}
    \end{align*}
    \item Выбор действия $a_t\sim p_t$ гарантирует регрет $O(\sqrt{T|A|\ln N})$.
  \end{itemize}
\end{frame}


\begin{frame}{Алгоритм HybridUCB}
  \begin{itemize}
    \item Расширение LinUCB: учитываем общие и специфические признаки.
    \item Модель: $E[r_{t,a}\mid z_{t,a},x_{t,a}] = z_{t,a}^\top\beta + x_{t,a}^\top\theta_a$.
    \item Расчёт UCB: 
    \[ p_{t,a} = z_{t,a}^\top\hat{\beta} + x_{t,a}^\top\hat{\theta}_a + \alpha\sqrt{s_{t,a}}, \]
    \[ s_{t,a} = z_{t,a}^\top A_0^{-1}z_{t,a} - 2z_{t,a}^\top A_0^{-1}B_a^\top A_a^{-1}x_{t,a} + x_{t,a}^\top A_a^{-1}x_{t,a} + x_{t,a}^\top A_a^{-1} B_a A_0^{-1} B_a^\top A_a^{-1} x_{t,a}. \]
    \item Обновления параметров:
    \begin{align*}
      A_0 &\leftarrow A_0 + B_{a_t}^\top A_{a_t}^{-1} B_{a_t} + z_{t,a_t}z_{t,a_t}^\top, \\
      b_0 &\leftarrow b_0 + B_{a_t}^\top A_{a_t}^{-1} b_{a_t} + r_{t,a_t}z_{t,a_t},
    \end{align*}
    и для выбранного $a_t$:
    \begin{align*}
      A_{a_t} &\leftarrow A_{a_t} + x_{t,a_t}x_{t,a_t}^\top, \\
      B_{a_t} &\leftarrow B_{a_t} + x_{t,a_t}z_{t,a_t}^\top, \\
      b_{a_t} &\leftarrow b_{a_t} + r_{t,a_t}x_{t,a_t}.
    \end{align*}
  \end{itemize}
\end{frame}
\begin{frame}{Алгоритм D-LinUCB}
  \begin{itemize}
    \item Модель: $X_t = \langle A_t, \theta^*_t\rangle + \eta_t$, где $\theta^*_t$ меняется во времени.
    \item Дисконтированные веса: $w_{t,s}=\gamma^{t-s}$, $0<\gamma<1$; регуляризация $\lambda>0$.
    \item Обновляем оценку параметра:
    \[
      \hat\theta_{t-1} = \arg\min_{\theta} \sum_{s=1}^{t-1} \gamma^{t-1-s}(X_s - \langle A_s,\theta\rangle)^2 + \lambda\|\theta\|^2_2.
    \]
    \item Определяем матрицы:
    \begin{aligned}
      V_{t-1} &= \sum_{s=1}^{t-1} \gamma^{t-1-s} A_s A_s^\top + \lambda I_d,\\
      \tilde V_{t-1} &= \sum_{s=1}^{t-1} \gamma^{2(t-1-s)} A_s A_s^\top + \lambda I_d.
    \end{aligned}
    \item Доверительный радиус при уровне $1-\delta$:
    \[
      \beta_{t-1} = \sqrt{\lambda}\,S + \sigma\sqrt{2\ln\frac{1}{\delta} + d\ln\Bigl(1 + \frac{L^2(1-\gamma^{2(t-1)})}{\lambda(1-\gamma^2)}\Bigr)}.
    \]
    \item Upper Confidence Bound:
    \[
      p_{t,a} = \langle a,\hat\theta_{t-1}\rangle
      + \beta_{t-1}\sqrt{a^\top V_{t-1}^{-1}\tilde V_{t-1}V_{t-1}^{-1}a}.
    \]
    \item Выбираем $A_t = \arg\max_{a\in A_t} p_{t,a}$, наблюдаем вознаграждение $X_t$.
    \item Рекурсивные обновления:
    \begin{aligned}
      V_t &= \gamma V_{t-1} + A_tA_t^\top + (1-\gamma)\lambda I_d,\\
      \tilde V_t &= \gamma^2 \tilde V_{t-1} + A_tA_t^\top + (1-\gamma^2)\lambda I_d,\\
      b_t &= \gamma b_{t-1} + X_t A_t,\\
      \hat\theta_t &= V_t^{-1} b_t.
    \end{aligned}
  \end{itemize}
\end{frame}

\begin{frame}{Сравнение}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{trahat.jpg}
  \end{center}
\end{frame}
\begin{frame}{Результаты}
 \begin{table}[ht]
    \centering
    \begin{tabular}{l c}
      \hline
      \textbf{Метод} & \textbf{Iris Regret} \\
      \hline
      UCB (\(\alpha=1.0\)) & 33.47 \\
      LinUCB (Disjoint, \(\alpha=1.0\)) & 12.93 \\
      LinUCB (Hybrid, \(\alpha=1.0\)) & 12.99 \\
      D-LinUCB (\(\alpha=1.0,\,\gamma=0.95\)) & 17.40 \\
      \hline
    \end{tabular}
    \caption{Кумулятивный регрет на Iris}
  \end{table}
  \vspace{1em}
  % Графики и регрет
  \begin{itemize}
    \item Различие между Hybrid и LinUCB очень мало $\Longrightarrow$ на Iris простая линейная модель уже почти полностью захватывает полезную информацию.
    \item D-LinUCB «забывает» старые наблюдения, что в стационарном Iris-примере приводит к небольшому ухудшению.
  \end{itemize}
\end{frame}
\begin{frame}{Заключение}
  \begin{itemize}
    \item Бандиты являются эффективным алгоритмом для решения задач, связанных с исследованием среды. Отличием от классического RL является то, что агент не изменяет её состояние.
    \item Контекстуальные бандиты, в отличие от бандитов, ориентирующихся исключительно на награду, позволяют дополнительно линейно учитывать признаки объектов.
Эксперименты доказывают, что это позволяет с высокой точностью решать различные задачи, в частности задачу классификации, где классы представимы как «ручки» бандита.
    \item Существует большое количество модификаций подхода. Гиперпараметры играют большую роль в сходимости алгоритма.
  \end{itemize}
\end{frame}
\begin{frame}{Распределение ролей}
  \begin{itemize}
    \item \textbf{Спицын Павел}: имплементация алгоритмов LinUCB и HybridUCB, проведение экспериментов и анализ результатов.
    \item \textbf{Мурзин Илья}: формализация задачи, разработка методологии эксперимента, подготовка датасетов.
    \item \textbf{Зинатулин Артём}: разработка инфраструктуры для онлайн-имитации, написание вспомогательных скриптов.
    \item \textbf{Никифорова Анна}: обзор и реализация алгоритмов UCB, $\epsilon$-greedy и EXP4, математические выкладки.
    \item \textbf{Глазов Иван}: подготовка визуализаций (графиков и таблиц).
    \item \textbf{Газизуллин Нияз}: обзор литературы по контекстным бандитам, написание введения и заключения.
  \end{itemize}
\end{frame}
\begin{frame}{Спасибо за внимание!}
  \begin{center}
    % Вписать по высоте 0.8 высоты текста слайда, сохраняя пропорции
    \includegraphics[height=0.8\textheight,keepaspectratio]{tensor.jpg}
  \end{center}
\end{frame}

\end{document}
